{
 "cells": [
  {
   "cell_type": "raw",
   "id": "43ad7d5d",
   "metadata": {},
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import pyperclip as clip\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e4a9f48",
   "metadata": {},
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00d8690c",
   "metadata": {},
   "source": [
    "cd /Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022\\ \\(CSV\\)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "364d2510",
   "metadata": {},
   "source": [
    "## Combining all Formatted Sheets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75e9bcf8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "PATH = os.getcwd()\n",
    "EXT = \"*.csv\"\n",
    "\n",
    "cols = ['date','time','sex','race','type','duration','city']\n",
    "count = 0\n",
    "\n",
    "\n",
    "for path, subdir, files in os.walk(PATH):\n",
    "    for file in glob(os.path.join(path, EXT)):\n",
    "        if 'ALL-' in file and 'AB953' in file:  \n",
    "            if count == 0: \n",
    "                main = pd.read_csv(file, index_col = None)\n",
    "                print(file)\n",
    "                main['city'] = f'{file[-30:]}'.replace('.csv','').split(\"/\")[1]\n",
    "                main.columns = map(str.lower, main.columns)\n",
    "                main = main.loc[:,cols]\n",
    "                count+=1\n",
    "                print(main.columns,main.shape,f'{file[-30:]} is starting main file\\n',main['time'].value_counts()[:50],'\\n\\n')\n",
    "\n",
    "            else:\n",
    "                try: \n",
    "                    df = pd.read_csv(file, index_col=None)\n",
    "                    df['city'] = f'{file[-30:]}'.replace('.csv','').split(\"/\")[1]\n",
    "                    df.columns = map(str.lower, df.columns)\n",
    "                    df = df.loc[:,cols]\n",
    "                    print(df.columns,df.shape,f'{file[-30:]} is starting main file\\n',df['time'].value_counts()[:50],'\\n\\n')\n",
    "                    main = pd.concat([main,df])\n",
    "                    print(f'{file[-30:]} concatenated!')\n",
    "                except:\n",
    "                    print(f'{file} failed to merge')\n",
    "                    pass\n",
    "                \n",
    "main = main[(main['city']!='working_main')]\n",
    "print(f'final shape of main is {main.shape}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c95024b",
   "metadata": {},
   "source": [
    "main.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "761a5583",
   "metadata": {},
   "source": [
    "main['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fefc8852",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "main.loc[main['type']=='middle eastern or south asian','type']=None\n",
    "main.loc[main['type']=='middle eastern or south asian','type']=None\n",
    "main.loc[main['duration']=='0-9','duration']=5\n",
    " \n",
    "\n",
    "type_list=[]\n",
    "main['type'] = main['type'].astype(str)\n",
    "\n",
    "for i in main['type']:\n",
    "    if '1' in i:\n",
    "        type_list.append('Moving')\n",
    "    elif '2' in i:\n",
    "        type_list.append('Equipment')\n",
    "    elif '3' in i:\n",
    "        type_list.append('Non-Moving')\n",
    "    \n",
    "    elif 'equipment' in i.lower():\n",
    "        type_list.append('Equipment')\n",
    "    elif 'non' in i.lower():\n",
    "        type_list.append('Non-Moving')\n",
    "    else:\n",
    "        type_list.append(None)\n",
    "main['type'] = type_list\n",
    "\n",
    "\n",
    "main.loc[main['race'] == 'Asian','race'] = 'asian'    \n",
    "main.loc[main['race'] == 'Black/African American','race'] = 'black/african american'    \n",
    "main.loc[main['race'] == 'black/african american','race'] = 'black/african american'    \n",
    "\n",
    "main.loc[main['race'] == 'Hispanic/Latino','race'] = 'hispanic/latino(a)'   \n",
    "main.loc[main['race'] == 'Hispanic/Latino/a','race'] = 'hispanic/latino(a)'    \n",
    "main.loc[main['race'] == 'White','race'] = 'white'\n",
    "main.loc[main['race'] == 'asian','race'] = 'asian'    \n",
    "main.loc[main['race'] == 'black/african american','race'] = 'black/african american'    \n",
    "main.loc[main['race'] == 'hispanic/latino','race'] = 'hispanic/latino(a)'    \n",
    "\n",
    "main.loc[main['race'] == 'white','race'] = 'white'\n",
    "\n",
    "main.loc[main['race'] == '1','race'] = 'asian'\n",
    "main.loc[main['race'] == '2','race'] = 'black/african american'\n",
    "main.loc[main['race'] == '3','race'] = 'hispanic/latino(a)'\n",
    "main.loc[main['race'] == 'hispanic/latino/a','race'] = 'hispanic/latino(a)'\n",
    "main.loc[main['race'] == '7','race'] = 'white'\n",
    "main.loc[main['race'] == 1,'race'] = 'asian'\n",
    "main.loc[main['race'] == 2,'race'] = 'black/african american'\n",
    "main.loc[main['race'] == 3,'race'] = 'hispanic/latino(a)'\n",
    "main.loc[main['race'] == 7,'race'] = 'white'\n",
    "\n",
    "main['race'] = main['race'].astype(str)\n",
    "mixed_list = []\n",
    "for i in main['race']:\n",
    "    if i not in ['white','asian','black/african american','hispanic/latino(a)']:\n",
    "        mixed_list.append('group 4')\n",
    "    else: \n",
    "        mixed_list.append(i)\n",
    "main['race'] = mixed_list\n",
    "      \n",
    "\n",
    "\n",
    "sex_list = []\n",
    "main['sex'] = main['sex'].astype(str)\n",
    "\n",
    "main.loc[main['sex'] == 1,'sex'] = 'male'\n",
    "main.loc[main['sex'] == 'Male','sex'] = 'male'\n",
    "main.loc[main['sex'] == 2,'sex'] = 'female'\n",
    "main.loc[main['sex'] == 'Female','sex'] = 'female'\n",
    "main.loc[main['sex']==3,'sex'] = None\n",
    "main.loc[main['sex']==4,'sex'] = None\n",
    "\n",
    "def sex_code(i):\n",
    "    if '1' in i:\n",
    "        return 'Male'\n",
    "    elif '2' in i:\n",
    "        return 'Female'\n",
    "    elif 'female' in i or 'Female' in i:\n",
    "        return 'Female'\n",
    "    elif 'male' in i or 'Male' in i:\n",
    "        return 'Male'\n",
    "    else: \n",
    "        return None\n",
    "        \n",
    "main['sex'] = [sex_code(i) if i is not None else i for i in main['sex']]\n",
    "# [f(x) if x is not None else '' for x in xs]        \n",
    "main['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49ab99cc",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "main.loc[main['time']=='00-04 HRS','time']= '06:00'\n",
    "main.loc[main['time']=='04-08 HRS','time']= '06:00'\n",
    "main.loc[main['time']=='08-12 HRS','time']= '10:00'\n",
    "main.loc[main['time']=='12-16 HRS','time']= '14:00'\n",
    "main.loc[main['time']=='16-20 HRS','time']= '18:00'\n",
    "main.loc[main['time']=='20-24 HRS','time']= '22:00'\n",
    "main.loc[main['time']=='middle eastern or south asian','time'] = '11:45'\n",
    "main.loc[main['date']=='middle eastern or south asian','date'] = '2019-04-20'\n",
    "\n",
    "# main['time'] = main['time'].astype(str)\n",
    "# main['time'] = [i[:-3] if len(i)==8 else i for i in main['time']]\n",
    "# main['time'] = pd.to_datetime(main['time']) \n",
    "\n",
    "# main['time'] = main['time'].dt.time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20a65de5",
   "metadata": {},
   "source": [
    "main.loc[main['duration']=='10-19','duration']=15\n",
    "main.loc[main['duration']=='20-30','duration']=25\n",
    "main.loc[main['duration']=='middle eastern or south asian','duration'] = 20\n",
    "\n",
    "main['duration'] = main.duration.replace({'minutes\\xa0':'',\n",
    "                                          'minutes\\xa0':'',\n",
    "                                          ' minutes':'',\n",
    "                                          ' minutes ':'',\n",
    "                                          ' Minutes ':'',\n",
    "                                          ' Minutes':'',\n",
    "                                          ' \\xa0':'',\n",
    "                                          '\\xa0':'',\n",
    "                                          ' min':'',\n",
    "                                          'min':'',\n",
    "                                          ' utes':'',\n",
    "                                          '0-9':6,\n",
    "                                          '10-19':15,\n",
    "                                          '20-30':25,\n",
    "                                          'Five':5,\n",
    "                                          'Over 30':45,\n",
    "                                          'One Hour':60,\n",
    "                                          'One hour':60,\n",
    "                                          '6/n':6},regex=True)\n",
    "\n",
    "main['duration'] = pd.to_numeric(main['duration'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85f52c9f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for col in main.columns:\n",
    "    print('\\n\\n',col,'\\n',main[col].value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40e423d9",
   "metadata": {},
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8620277a",
   "metadata": {},
   "source": [
    "cd /Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022\\ \\(CSV\\)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e68dce04",
   "metadata": {},
   "source": [
    "main = main[main['city']!='LAPD']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d965be1",
   "metadata": {},
   "source": [
    "main.to_csv('working_main.csv',index=False)\n",
    "print('working_main saved!',main.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f10ef394",
   "metadata": {},
   "source": [
    "## Method #1 LOG REGRESSION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bf52c41",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "import statsmodels.formula.api as smf\n",
    "import statistics as st \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "from astral import LocationInfo\n",
    "import datetime\n",
    "from astral.sun import sun\n",
    "from astral import LocationInfo\n",
    "from alive_progress import alive_bar\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83b4ae5e",
   "metadata": {},
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bbb638d",
   "metadata": {},
   "source": [
    "cd /Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022\\ \\(CSV\\)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f937af7b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "working_main = pd.read_csv('working_main.csv')\n",
    "print(working_main.columns,'\\n',working_main.shape,'\\n',len(working_main.time))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbe7efd6",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "working_main"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c58cdaf0",
   "metadata": {},
   "source": [
    "time = []\n",
    "for i in range(len(working_main['time'])): \n",
    "    current = working_main.loc[i,'time']\n",
    "    \n",
    "    if len(working_main.loc[i,'time']) < 8:\n",
    "        time.append(current + ':00')\n",
    "    elif len(working_main.loc[i,'time']) > 8:\n",
    "        time.append(current[11:19])\n",
    "    else:\n",
    "        time.append(current)\n",
    "        \n",
    "working_main['time'] = time\n",
    "working_main['time'] = pd.to_datetime(working_main['time'],format=\"%H:%M:%S\")\n",
    "print('len of time column is:',len(working_main.time),'\\n sum of null time values is:',working_main['time'].isna().sum())\n",
    "working_main"
   ]
  },
  {
   "cell_type": "raw",
   "id": "257ade99",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "working_main = working_main.rename(columns={'city':'agency'})\n",
    "\n",
    "def city_from_agency_check(df):\n",
    "    city_str = []\n",
    "    lat_str = []\n",
    "    lon_str = []\n",
    "    wave_str = []\n",
    "    \n",
    "    for i in df['agency']:\n",
    "        if 'ALL-SJPD-AB953' in i:\n",
    "            city_str.append('San Jose')\n",
    "            lat_str.append(37.3387)\n",
    "            lon_str.append(-121.8853)\n",
    "            wave_str.append(2)\n",
    "        elif 'ALL-LBPD-AB953' in i:\n",
    "            city_str.append('Long Beach')\n",
    "            lat_str.append(33.7701)\n",
    "            lon_str.append(-118.1937)\n",
    "            wave_str.append(2)\n",
    "        elif 'ALL-OAKLAND_PD-AB953' in i:\n",
    "            city_str.append('Oakland')\n",
    "            lat_str.append(37.8044)\n",
    "            lon_str.append(-122.2712)\n",
    "            wave_str.append(2)\n",
    "        elif 'Berkeley PD' in i:\n",
    "            city_str.append('Berkeley')\n",
    "            lat_str.append(37.8715)\n",
    "            lon_str.append(-122.2730)\n",
    "            wave_str.append(3)\n",
    "        elif 'ALL-MARIN-AB953' in i:\n",
    "            city_str.append('Marin')\n",
    "            lat_str.append(38.0834)\n",
    "            lon_str.append(-122.7633)\n",
    "            wave_str.append(3)\n",
    "        elif 'Davis PD' in i:\n",
    "            city_str.append('Davis')\n",
    "            lat_str.append(38.5449)\n",
    "            lon_str.append(-121.7405)\n",
    "            wave_str.append(3)\n",
    "        elif 'ALL-RIVERSIDE-AB953' in i:\n",
    "            city_str.append('Riverside')\n",
    "            lat_str.append(33.9806)\n",
    "            lon_str.append(-117.3755)\n",
    "            wave_str.append(1)\n",
    "        elif 'SDPD' in i:\n",
    "            city_str.append('San Diego')\n",
    "            lat_str.append(32.7157)\n",
    "            lon_str.append(-117.1611)\n",
    "            wave_str.append(1)\n",
    "        elif 'ALL-SFPD-AB953' in i:\n",
    "            city_str.append('San Francisco')\n",
    "            lat_str.append(37.7749)\n",
    "            lon_str.append(-122.4194)\n",
    "            wave_str.append(1)\n",
    "        elif 'ALL-LAPD-AB953' in i:\n",
    "            city_str.append('Los Angeles')\n",
    "            lat_str.append(34.0522)\n",
    "            lon_str.append(-118.2437)\n",
    "            wave_str.append(1)\n",
    "        \n",
    "    df['city']=city_str\n",
    "    df['lat']=lat_str\n",
    "    df['lon']=lon_str\n",
    "    df['wave']=wave_str\n",
    "    \n",
    "    pd.option_context('display.precision', 10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "working_main = city_from_agency_check(working_main)\n",
    "working_main"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb4ff163",
   "metadata": {},
   "source": [
    "working_main['date'].isna().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd00cb03",
   "metadata": {},
   "source": [
    "# %%timeit\n",
    "# start = time.time()\n",
    "\n",
    "sunset_list = []\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for i in working_main['date']:\n",
    "    year = i.year\n",
    "    month = i.month\n",
    "    day = i.day\n",
    "\n",
    "    name = working_main['city'][counter]\n",
    "    lat = working_main['lat'][counter]\n",
    "    lon = working_main['lon'][counter]\n",
    "\n",
    "    loc = LocationInfo(name=name, region='CA, USA', timezone='America/Los_Angeles', #https://en.wikipedia.org/wiki/List_of_tz_database_time_zones\n",
    "                       latitude=lat, longitude=lon)\n",
    "    \n",
    "\n",
    "\n",
    "    s = sun(loc.observer, date=datetime.date(year, month, day), tzinfo=loc.timezone)\n",
    "    for key in ['sunset']:\n",
    "        sunset_list.append(s[key].time())\n",
    "        \n",
    "    counter+=1\n",
    "# working_main['sunsettime'] = sunset_list\n",
    "# print(f'that whole process took {(time.time()-start)/60} minutes')\n",
    "# sunset_list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ed24b81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4221ceb9",
   "metadata": {},
   "source": [
    "# https://www.geeksforgeeks.org/reading-and-writing-json-to-a-file-in-python/\n",
    "import json\n",
    "\n",
    "sunset_list_save = [str(i) for i in sunset_list]\n",
    "sunsets_jsonString = json.dumps(sunset_list_save)\n",
    "\n",
    "with open(\"sunset_times_temp.json\", \"w\") as outfile:\n",
    "    outfile.write(sunsets_jsonString)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c27949e",
   "metadata": {},
   "source": [
    "import json\n",
    "with open('data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef411c37",
   "metadata": {},
   "source": [
    "df = working_main\n",
    "print(type(df))\n",
    "dog = str(sunset_list)\n",
    "df['sunset'] = pd.to_datetime(dog,format=\"%H:%M\")\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c76138b3",
   "metadata": {},
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5a626e9",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "date_to_subtract = datetime.datetime(1900, 1, 1)\n",
    "\n",
    "working_main['totalminutes_stop_time'] = [((i - date_to_subtract).total_seconds()/60) for i in working_main['time']]\n",
    "working_main['totalminutes_sunsettime'] = [((i - date_to_subtract).total_seconds()/60) for i in working_main['sunsettime']]\n",
    "working_main['time_to_sunset'] = working_main['totalminutes_sunsettime'] - working_main['totalminutes_stop_time']\n",
    "\n",
    "print(working_main['time_to_sunset'].isna().sum())\n",
    "working_main.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cad6fd8e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df = pd.read_csv('working_times_VOD.csv')\n",
    "# df = df.iloc[:,1:]\n",
    "df\n",
    "# df.to_csv('working_times_VOD.csv',index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee22bdb6",
   "metadata": {},
   "source": [
    "df = working_main\n",
    "sunset_time2 = [str(i)[:-13] for i in sunset_list]\n",
    "sunset_time_dt = pd.to_datetime(sunset_time2)\n",
    "df['sunddsettime'] = sunset_time_dt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98a5c026",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "df['sunsettime'] = [str(i)[-8:] for i in df['sunsettime']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "906fb237",
   "metadata": {},
   "source": [
    "type(df['time'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "742b0c8e",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "working_main = df\n",
    "working_main['time'] = pd.to_datetime(working_main['date'],format='%H:%M')\n",
    "working_main['sunsettime'] = pd.to_datetime(working_main['sunsettime'],format='%H:%M')\n",
    "\n",
    "working_main['tosunset'] = (working_main['sunsettime'] - working_main['time'])\n",
    "working_main\n",
    "\n",
    "# tosunset = [str(i)[:-13] for i in working_main['tosunset']]\n",
    "# tosunsetdt = (pd.to_datetime(tosunset,format='%H:%M')).total_seconds()/60\n",
    "# working_main['tosunset'] = tosunsetdt\n",
    "\n",
    "# working_main['time'] = working_main.time.dt.strftime('%H:%M')\n",
    "# working_main['sunsettime'] = working_main.sunsettime.dt.strftime('%H:%M')\n",
    "\n",
    "# working_main.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83353ff9",
   "metadata": {},
   "source": [
    "working_main.to_csv('working_times_VOD.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d89ea1a",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print(working_main.shape)\n",
    "# one_hot_encoded_main = pd.get_dummies(working_main, columns = ['sex','race'],drop=False,prefix='') #https://www.geeksforgeeks.org/ml-one-hot-encoding-of-datasets-in-python/\n",
    "VOD = working_main[working_main['type']!='Non-Moving'][['datetime','race']]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a529ce6",
   "metadata": {},
   "source": [
    "race_options = ['white','black','hispanic','asian','report_risk_groups','bipoc']\n",
    "\n",
    "\n",
    "for race in race_options:\n",
    "    formula = f\"_black/african american ~ C({race}, Treatment(reference=0)) + perceivedage\"\n",
    "    log_reg = smf.logit(formula, data = df).fit()\n",
    "    results = log_reg.summary()\n",
    "    OR = pd.DataFrame(\n",
    "        {\n",
    "            \"OR\": log_reg.params,\n",
    "            \"Lower CI\": log_reg.conf_int()[0],\n",
    "            \"Upper CI\": log_reg.conf_int()[1],\n",
    "        },\n",
    "    )\n",
    "    OR = np.exp(OR)\n",
    "    \n",
    "    print(f\"\\n\\n{race} model (LARGE)\\n{OR}\\n\\n\\n{results}\\n\\n\\n\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0cb1efe",
   "metadata": {},
   "source": [
    "with_VOD = pd.read_csv('working_times_VOD.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7ac1b3c",
   "metadata": {},
   "source": [
    "with_VOD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7dc2f03",
   "metadata": {},
   "source": [
    "## Method #2 VISUALIZATION AROUND DUSK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6812089",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VOD",
   "language": "python",
   "name": "vod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
