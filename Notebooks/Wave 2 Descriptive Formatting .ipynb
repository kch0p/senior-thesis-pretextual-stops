{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "28f88b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bf93c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIPA_factors = 'ORI number\\nDate, time, and duration of the stop\\nLocation of stop\\nPerceived race or ethnicity of person stopped\\nPerceived gender of person stopped\\nPerson stopped perceived to be LGBT\\nPerceived age of person stopped\\nPerson stopped has limited or no English fluency\\nPerceived or known disability or person stopped\\nReason for stop\\nStop made in response to a call for service\\nActions taken by officer during stop\\nResults of stop\\nOfficer’s Identification (ID) Number\\nOfficer’s years of experience\\nType of assignment of officer'\n",
    "# RIPA_cols_to_keep = RIPA_factors.splitlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5b46c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIPA_cols_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78222fc9",
   "metadata": {},
   "source": [
    "# WAVE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f0f7d",
   "metadata": {},
   "source": [
    "## Long Beach PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "37c4c59d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karatechop\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "95a18412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022 (CSV)/Wave 2/Long Beach Police Dept\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022 (CSV)/Wave 2/Long Beach Police Dept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1e8ef467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stop ID', 'Person ID', 'Stop Date', 'Stop Time', 'Stop Duration',\n",
       "       'Stop In Response To CFS', 'Block Number', 'Street', 'Intersection',\n",
       "       'Highway Exit', 'Landmark', 'City', 'Is School', 'School Name',\n",
       "       'Is Student', 'Perceived Age', 'Perceived Gender',\n",
       "       'Gender Non-conforming', 'Perceived LGBT', 'Perceived Limited English',\n",
       "       'Actions Taken', 'Num Actions Taken', 'Did Consent for Person Search',\n",
       "       'Did Consent for Property Search', 'Perceived Races',\n",
       "       'Num Perceived Races', 'Perceived Race Simplified',\n",
       "       'All Basis for Search', 'All Basis for Property Seized',\n",
       "       'All Contrabands or Evidences', 'Number of Contrabands/Evidences',\n",
       "       'All Disabilities', 'Number of Disabilities',\n",
       "       'All Property Types Seized', 'Number of Property Types Seized',\n",
       "       'All Reasons for Stop', 'All Reasons for Stop Description',\n",
       "       'All Reasons for Stop Code', 'All Reasons for Stop Code Text',\n",
       "       'All Reason for Stop Detail', 'Number of Reasons for Stop',\n",
       "       'Reason for Stop Simplified', 'All Results of Stop',\n",
       "       'All Result of Stop Codes', 'All Result of Stop Code Text',\n",
       "       'Result of Stop Simplified', 'Was Person Detained', 'Was Action Taken',\n",
       "       'Number of Results of Stop', 'Record Year', 'Stop Hour', 'Time of Day',\n",
       "       'Was Person Handcuffed', 'Was Person or Property Searched',\n",
       "       'Was Person Removed From Vehicle or Not', 'Stop Result in Arrest',\n",
       "       'Stop Result in Citation', 'Stop Result in Warning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb19_20 = pd.read_csv('lbpd-ripa-data-annual.csv')\n",
    "lb19_20.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f79324e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no dropped pid dupes\n",
      "lbpd is done! LBPD shape is (36670, 14)\n",
      "LBPD saved!\n"
     ]
    }
   ],
   "source": [
    "def convert_simplify_LB(df):\n",
    "    i = df\n",
    "    i = i.rename(columns={'Stop ID':'Stop ID',\n",
    "                          'Stop Date':'date',\n",
    "                          'Stop Time':'time',\n",
    "                          'Time of Day':'Time',\n",
    "                          'Stop In Response To CFS':'service call',\n",
    "                          'Stop Duration':'Duration',\n",
    "                          'Stop ID':'Stop ID',\n",
    "                          'Person ID':'PID',\n",
    "                          'Perceived Race Simplified':'race',\n",
    "                          'Perceived Gender':'sex',\n",
    "                          'Perceived Age':'age',\n",
    "                          'All Reason for Stop Detail':'type',\n",
    "                          'All Reasons for Stop':'reason',\n",
    "#                           'Person Primary Reason Suspicion Type Suspicion Type Value':'basis',\n",
    "                          'Actions Taken':'actions taken',\n",
    "                          'All Basis for Search':'search basis',\n",
    "#                           'szrBase':'seizure basis',\n",
    "                          'All Property Types Seized':'property seized',\n",
    "#                           'evid':'evidence',\n",
    "                          'All Results of Stop':'result',\n",
    "                          'All Result of Stop Code Text':'offense code',\n",
    "                          'Is Student':'student'})\n",
    "\n",
    "    i = i[(i['service call']!='Yes')\\\n",
    "          & ((i['type']=='Moving Violation') | (i['type']=='Equipment Violation') | (i['type']=='Non-moving Violation, including Registration Violation'))\\\n",
    "          &  (i['reason']=='Traffic Violation')\\\n",
    "          &  (i['student']!='Yes')]\n",
    "\n",
    "    i.loc[i['type'] == 'Moving Violation','type'] = '1 Moving'\n",
    "    i.loc[i['type'] == 'Equipment Violation','type'] = '2 Equipment'\n",
    "    i.loc[i['type'] == 'Non-moving Violation, including Registration Violation','type'] = '3 Non-Moving'\n",
    "    \n",
    "    \n",
    "    try:     \n",
    "        i.loc[i['race'] == '1','race'] = 'asian'\n",
    "        i.loc[i['race'] == '2','race'] = 'black/african american'\n",
    "        i.loc[i['race'] == '3','race'] = 'hispanic/latino(a)'\n",
    "        i.loc[i['race'] == '4','race'] = 'middle eastern or south asian'\n",
    "        i.loc[i['race'] == '5','race'] = 'native american'\n",
    "        i.loc[i['race'] == '6','race'] = 'pacific islander'\n",
    "        i.loc[i['race'] == '7','race'] = 'white'\n",
    "        i.loc[i['race'] == 1,'race'] = 'asian'\n",
    "        i.loc[i['race'] == 2,'race'] = 'black/african american'\n",
    "        i.loc[i['race'] == 3,'race'] = 'hispanic/latino(a)'\n",
    "        i.loc[i['race'] == 4,'race'] = 'middle eastern or south asian'\n",
    "        i.loc[i['race'] == 5,'race'] = 'native american'\n",
    "        i.loc[i['race'] == 6,'race'] = 'pacific islander'\n",
    "        i.loc[i['race'] == 7,'race'] = 'white'\n",
    "    except: \n",
    "        print('race switch failed')\n",
    "        pass\n",
    "    \n",
    "    try: #mixed list type 1\n",
    "        mixed_list = []\n",
    "        for check in i['race']:\n",
    "            if len(check.split(','))>1:\n",
    "                mixed_list.append('mixed')\n",
    "            else: \n",
    "                mixed_list.append(check)\n",
    "        i['race'] = mixed_list\n",
    "        i['race'] = i['race'].str.lower()\n",
    "    except:\n",
    "        try: #mixed list type 2\n",
    "            mixed_list = []\n",
    "            for check in i['race']:\n",
    "                if len(check.split('or'))>1:\n",
    "                    mixed_list.append(check.split('or')[0].replace(' ',''))\n",
    "                else: \n",
    "                    mixed_list.append(check)\n",
    "            i['race'] = mixed_list\n",
    "            i['race'] = i['race'].str.lower()\n",
    "        except:    \n",
    "            print('no mixed race changes')\n",
    "            pass\n",
    "\n",
    "    \n",
    "#     try:\n",
    "#         i['Date'] = pd.to_datetime(i['Date'])\n",
    "#         i['Time'] = i['Date'].dt.time\n",
    "#     except: \n",
    "#         try: \n",
    "#             i['Time'] = i['Date'].dt.time\n",
    "#         except:\n",
    "#             print('no time changes')\n",
    "#             pass\n",
    "\n",
    "    \n",
    "    try: \n",
    "        i = i.drop_duplicates(subset=['stop_id'], keep='first')\n",
    "    except: \n",
    "        print('no dropped pid dupes')\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    output_df = i[['date', 'time','Stop ID','Duration','PID','race', 'sex','age','type',\n",
    "                   'reason', 'actions taken', 'search basis','property seized', \n",
    "                   'result']]\n",
    "#     'basis','seizure basis','evidence','basis','Experience'\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "import glob\n",
    "path = os.getcwd()\n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "for i in files: \n",
    "    if 'AB953' not in i:\n",
    "        LBPD = convert_simplify_LB(pd.read_csv(i))\n",
    "        print(f'lbpd is done! LBPD shape is {LBPD.shape}')\n",
    "LBPD.to_csv('ALL-LBPD-AB953.csv',index=False)\n",
    "print('LBPD saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be665d",
   "metadata": {},
   "source": [
    "## Oakland PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8362d7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karatechop\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e5864999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022 (CSV)/Wave 2/Oakland PD\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022 (CSV)/Wave 2/Oakland PD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "118d0110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL-OAKLAND_PD-AB953.csv\r\n",
      "Cleaned-Stop-Data-2021-for-PRR-Requests(1).csv\r\n",
      "Q1-2022-Stop-Data-for-PRRs-and-Website.csv\r\n",
      "Q2-Stop-Data-Cleaned.csv\r\n",
      "Stop_Data_for_Release_Jan_2017_to_Feb_2021_1_2.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8fbe1208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oak17_21 = pd.read_csv('Stop_Data_for_Release_Jan_2017_to_Feb_2021_1_2.csv').sort_values(by=['contactdate'])\n",
    "oak21 = pd.read_csv('Stop_Data_for_Release_Jan_2017_to_Feb_2021_1_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3ef0358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oak21['Datetime'] = pd.to_datetime(oak21['contactdate'] + ' ' + oak21['contacttime_FIX'])\n",
    "oak21['contactdate'] = oak21['Datetime'].dt.date\n",
    "oak21['contacttime_FIX'] = oak21['Datetime'].dt.time\n",
    "\n",
    "oak17_21['Datetime'] = pd.to_datetime(oak17_21['contactdate'] + ' ' + oak17_21['contacttime_FIX'])\n",
    "oak17_21['contactdate'] = oak17_21['Datetime'].dt.date\n",
    "oak17_21['contacttime_FIX'] = oak17_21['Datetime'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "465aed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oak21.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6746a816",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no student\n",
      "no dropped pid dupes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56506, 17)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_simplify_OAK21(df):\n",
    "    i = df\n",
    "    i = i.rename(columns={'Unique ID':'Stop ID',\n",
    "                          'contactdate':'date',\n",
    "                          'contacttime_FIX':'time',\n",
    "                          'assignmenttype_AB953':'assignment',\n",
    "                          'experienceyears_AB953':'Experience',\n",
    "                          'intelligenceled':'service call',\n",
    "                          'Student':'student',\n",
    "                          'intelligenceledfactor':'service call',\n",
    "                          'Stop Duration':'Duration',\n",
    "                          'subject_durationofencounter_FIX':'Duration',\n",
    "                          'Stop ID':'Stop ID',\n",
    "                          'Person ID':'PID',\n",
    "                          'perceived_race_AB953':'race',\n",
    "                          'RacePerceivedPrior':'race perceived prior',\n",
    "                          'perceived_sex_AB953':'sex',\n",
    "                          'perceived_age_AB953':'age',\n",
    "                          'TypeTraffic_AB953':'type',\n",
    "                          'TypeTraffic_detail_AB953':'type',\n",
    "                          'ReasonForStop_OPD':'reason',\n",
    "#                           'subject_reasonforencounter_AB953':'reason',\n",
    "#                           'suspicion_type_AB953':'basis',\n",
    "                          'stop_relatedactions_AB953':'actions taken',\n",
    "                          'SearchBasis_detail_AB953':'search basis',\n",
    "                          'BasisForPropertySeizure_AB953':'seizure basis',\n",
    "                          'PropertySeized_detail_AB953':'property seized',\n",
    "                          'EvidDisc_detail_AB953':'evidence',\n",
    "                          'resultofstop_OPD':'result'})\n",
    "\n",
    "    i = i[i['reason']=='Traffic Violation']\n",
    "    \n",
    "    try:\n",
    "        i = i[i['student']!=1]\n",
    "    except:\n",
    "        print('no student')\n",
    "        pass\n",
    "\n",
    "    i.loc[i['type'] == 'Moving Violation','type'] = '1 Moving'\n",
    "    i.loc[i['type'] == 'Equipment Violation','type'] = '2 Equipment'\n",
    "    i.loc[i['type'] == 'Non-moving Violation, including Registration Violation','type'] = '3 Non-Moving'\n",
    "    \n",
    "       \n",
    "    race_list = []\n",
    "    for race in i['race']:\n",
    "        try:\n",
    "            if len(race)>2:\n",
    "                race_list.append('mixed')\n",
    "            else:\n",
    "                race_list.append(race)\n",
    "        except:\n",
    "            try:\n",
    "                race_str = race.str.replace(',','')\n",
    "                race_list.append(race_str)\n",
    "            except:\n",
    "                    race_list.append(race)\n",
    "    \n",
    "\n",
    "    \n",
    "    i['race'] = race_list\n",
    "    i['race'] = i['race'].replace(',','', regex=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    try:     \n",
    "        i.loc[i['race'] == '1','race'] = 'asian'\n",
    "        i.loc[i['race'] == '2','race'] = 'black/african american'\n",
    "        i.loc[i['race'] == '3','race'] = 'hispanic/latino(a)'\n",
    "        i.loc[i['race'] == '4','race'] = 'middle eastern or south asian'\n",
    "        i.loc[i['race'] == '5','race'] = 'native american'\n",
    "        i.loc[i['race'] == '6','race'] = 'pacific islander'\n",
    "        i.loc[i['race'] == '7','race'] = 'white'\n",
    "        i.loc[i['race'] == 1,'race'] = 'asian'\n",
    "        i.loc[i['race'] == 2,'race'] = 'black/african american'\n",
    "        i.loc[i['race'] == 3,'race'] = 'hispanic/latino(a)'\n",
    "        i.loc[i['race'] == 4,'race'] = 'middle eastern or south asian'\n",
    "        i.loc[i['race'] == 5,'race'] = 'native american'\n",
    "        i.loc[i['race'] == 6,'race'] = 'pacific islander'\n",
    "        i.loc[i['race'] == 7,'race'] = 'white'\n",
    "    except: \n",
    "        print('race switch failed')\n",
    "        pass\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         i['Date'] = pd.to_datetime(i['Date'])\n",
    "#         i['Time'] = i['Date'].dt.time\n",
    "#     except: \n",
    "#         try: \n",
    "#             i['Time'] = i['Date'].dt.time\n",
    "#         except:\n",
    "#             print('no time changes')\n",
    "#             pass\n",
    "\n",
    "    \n",
    "    try: \n",
    "        i = i.drop_duplicates(subset=['stop_id'], keep='first')\n",
    "    except: \n",
    "        print('no dropped pid dupes')\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    output_df = i[['date', 'time','Stop ID','Duration','race', 'sex','age','type',\n",
    "                   'reason', 'actions taken', 'search basis','property seized', 'race perceived prior',\n",
    "                   'result','Experience','seizure basis','evidence']]\n",
    "#     'basis','seizure basis','evidence'\n",
    "\n",
    "    return output_df\n",
    "\n",
    "OAK_21 = convert_simplify_OAK21(oak21)\n",
    "OAK_21.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e411d78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "black/african american           8321\n",
       "hispanic/latino(a)               5100\n",
       "white                            2196\n",
       "asian                            1110\n",
       "middle eastern or south asian     640\n",
       "mixed                             244\n",
       "pacific islander                  123\n",
       "native american                    10\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OAK_21['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5d5334f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oak17_21.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1fe2db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no student\n",
      "no dropped pid dupes\n",
      "(68527, 17)\n",
      "save successful\n"
     ]
    }
   ],
   "source": [
    "def convert_simplify_OAK17(df):\n",
    "    i = df\n",
    "    i = i.rename(columns={'Unique ID':'stop iD',\n",
    "                          'contactdate':'date',\n",
    "                          'contacttime_FIX':'time',\n",
    "                          'assignmenttype_AB953':'assignment',\n",
    "                          'experienceyears_AB953':'experience',\n",
    "                          'intelligenceledfactor':'service call',\n",
    "                          'Student':'student',\n",
    "                          'intelligenceledfactor':'service call',\n",
    "                          'subject_durationofencounter_FIX':'duration',\n",
    "                          'subject_durationofencounter_FIX':'duration',\n",
    "                          'Stop ID':'Stop ID',\n",
    "                          'Person ID':'PID',\n",
    "                          'perceived_race_AB953':'race',\n",
    "                          'RacePerceivedPrior':'race perceived prior',\n",
    "                          'perceived_sex_AB953':'sex',\n",
    "                          'perceived_age_AB953':'age',\n",
    "                          'TypeTraffic_detail_AB953':'type',\n",
    "                          'TypeTraffic_detail_AB953':'type',\n",
    "                          'ReasonForStop_OPD':'reason',\n",
    "#                           'subject_reasonforencounter_AB953':'reason',\n",
    "#                           'suspicion_type_AB953':'basis',\n",
    "                          'stop_relatedactions_AB953':'actions taken',\n",
    "                          'SearchBasis_detail_AB953':'search basis',\n",
    "                          'BasisForPropertySeizure_AB953':'seizure basis',\n",
    "                          'PropertySeized_detail_AB953':'property seized',\n",
    "                          'EvidDisc_detail_AB953':'evidence',\n",
    "                          'resultofstop_OPD':'result'})\n",
    "\n",
    "    i = i[(i['reason']=='Traffic Violation')\\\n",
    "            & (i['assignment']=='Patrol, traffic enforcement, field operations')]\n",
    "    \n",
    "    try:\n",
    "        i = i[i['student']!=1]\n",
    "    except:\n",
    "        print('no student')\n",
    "        pass\n",
    "\n",
    "    i.loc[i['type'] == 'Moving Violation','type'] = '1 Moving'\n",
    "    i.loc[i['type'] == 'Equipment Violation','type'] = '2 Equipment'\n",
    "    i.loc[i['type'] == 'Non-moving Violation, including Registration Violation','type'] = '3 Non-Moving'\n",
    "    \n",
    "    race_list = []\n",
    "    for race in i['race']:\n",
    "        try:\n",
    "            if len(race)>2:\n",
    "                race_list.append('mixed')\n",
    "            else:\n",
    "                race_list.append(race)\n",
    "        except:\n",
    "            try:\n",
    "                race_str = race.str.replace(',','')\n",
    "                race_list.append(race_str)\n",
    "            except:\n",
    "                    race_list.append(race)\n",
    "    \n",
    "\n",
    "    \n",
    "    i['race'] = race_list\n",
    "    i['race'] = i['race'].replace(',','', regex=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    try:     \n",
    "        i.loc[i['race'] == '1','race'] = 'asian'\n",
    "        i.loc[i['race'] == '2','race'] = 'black/african american'\n",
    "        i.loc[i['race'] == '3','race'] = 'hispanic/latino(a)'\n",
    "        i.loc[i['race'] == '4','race'] = 'middle eastern or south asian'\n",
    "        i.loc[i['race'] == '5','race'] = 'native american'\n",
    "        i.loc[i['race'] == '6','race'] = 'pacific islander'\n",
    "        i.loc[i['race'] == '7','race'] = 'white'\n",
    "        i.loc[i['race'] == 1,'race'] = 'asian'\n",
    "        i.loc[i['race'] == 2,'race'] = 'black/african american'\n",
    "        i.loc[i['race'] == 3,'race'] = 'hispanic/latino(a)'\n",
    "        i.loc[i['race'] == 4,'race'] = 'middle eastern or south asian'\n",
    "        i.loc[i['race'] == 5,'race'] = 'native american'\n",
    "        i.loc[i['race'] == 6,'race'] = 'pacific islander'\n",
    "        i.loc[i['race'] == 7,'race'] = 'white'\n",
    "    except: \n",
    "        print('race switch failed')\n",
    "        pass\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         i['Date'] = pd.to_datetime(i['Date'])\n",
    "#         i['Time'] = i['Date'].dt.time\n",
    "#     except: \n",
    "#         try: \n",
    "#             i['Time'] = i['Date'].dt.time\n",
    "#         except:\n",
    "#             print('no time changes')\n",
    "#             pass\n",
    "\n",
    "    \n",
    "    try: \n",
    "        i = i.drop_duplicates(subset=['stop_id'], keep='first')\n",
    "    except: \n",
    "        print('no dropped pid dupes')\n",
    "        pass\n",
    "    \n",
    "    output_df = i[['date','time', 'race', 'sex','age','type',\n",
    "                   'reason', 'actions taken', 'search basis','property seized', 'race perceived prior',\n",
    "                   'result','seizure basis','evidence']]\n",
    "#     'basis','seizure basis','evidence'\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "OAKLAND = pd.concat([OAK_21,convert_simplify_OAK17(oak17_21)],axis=0)\n",
    "print(OAKLAND.shape)\n",
    "OAKLAND.to_csv('ALL-OAKLAND_PD-AB953.csv',index=False)\n",
    "print('save successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99255a3c",
   "metadata": {},
   "source": [
    "## SJPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fb6a54ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karatechop\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d1ab3a8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022 (CSV)/Wave 2/SJPD CAU (Crime Analysis Unit)\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022 (CSV)/Wave 2/SJPD CAU (Crime Analysis Unit)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "34f7bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL-SJPD-AB953.csv\r\n",
      "Attachment_1-_2019_RIPA(1).csv\r\n",
      "Attachment_3-_AB_953_Technical_Data_Dictionary-EXTERNAL.xlsx\r\n",
      "Attachment_4-_2020_RIPA-_Updated.csv\r\n",
      "Attachment_5-_2021_RIPA(1).csv\r\n",
      "\u001b[34moriginal\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0e5e20fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/yc8lq2qx2ks3ck292tbf6wtm0000gn/T/ipykernel_13584/3559708382.py:1: DtypeWarning: Columns (6,14,15,18,19,21,27,36,41,42,43,44,46,49,55,64,66,68,69,70,71,72,73,74,77,83,92,94,95,96,97,98,99,100,101,102,105,120,122,123,124,125,126,127,128,129,130,136,138,140,142,148,149,150,151,152,153,154,155,156,157,159,164,166,168,170,176,177,178,179,180,181,182,183,184,186,187,192,194,196,198,204,205,207,208,209,210,211,215,220,222,224,226,232,233,235,236,237,238,239,243,248,250,252,254,260,261,263,264,265,266,271,276,278,280,282,289,291,292,293,294,299,304,306,308,310,317,332,334,336,338,345,360,362,364,366,373,388,390,392,394,401,411,416,418,420,422,429,444,446,448,450,457,467) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv('Attachment_1-_2019_RIPA(1).csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('Attachment_1-_2019_RIPA(1).csv')\n",
    "test['Perceived Race or Ethnicity'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8b36d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/yc8lq2qx2ks3ck292tbf6wtm0000gn/T/ipykernel_13584/2589367042.py:10: DtypeWarning: Columns (18,19,27,44,49,64,66,68,69,70,71,72,73,74,75,77,92,94,97,98,99,102,122,123,130,136,138,140,142,149,150,151,155,157,164,166,168,170,177,178,179,192,194,196,198,205,206,207,220,222,224,226,233,234,235,248,250,252,254,261) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, index_col=None)\n",
      "/var/folders/td/yc8lq2qx2ks3ck292tbf6wtm0000gn/T/ipykernel_13584/2589367042.py:10: DtypeWarning: Columns (6,14,15,18,19,21,27,36,41,42,43,44,46,49,55,64,66,68,69,70,71,72,73,74,77,83,92,94,95,96,97,98,99,100,101,102,105,120,122,123,124,125,126,127,128,129,130,136,138,140,142,148,149,150,151,152,153,154,155,156,157,159,164,166,168,170,176,177,178,179,180,181,182,183,184,186,187,192,194,196,198,204,205,207,208,209,210,211,215,220,222,224,226,232,233,235,236,237,238,239,243,248,250,252,254,260,261,263,264,265,266,271,276,278,280,282,289,291,292,293,294,299,304,306,308,310,317,332,334,336,338,345,360,362,364,366,373,388,390,392,394,401,411,416,418,420,422,429,444,446,448,450,457,467) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, index_col=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perceived Race or Ethnicity' 'Perceived Race or Ethnicity.1'\n",
      " 'Perceived Race or Ethnicity.2' 'Perceived Race or Ethnicity.3'\n",
      " 'Perceived Race or Ethnicity.4' 'Perceived Race or Ethnicity.5'\n",
      " 'Perceived Race or Ethnicity.6' 'Perceived Race or Ethnicity.7'\n",
      " 'Perceived Race or Ethnicity.8' 'Perceived Race or Ethnicity.9'\n",
      " 'Perceived Race or Ethnicity.10' 'Perceived Race or Ethnicity.11'\n",
      " 'Perceived Race or Ethnicity.12' 'Perceived Race or Ethnicity.13'\n",
      " 'Perceived Race or Ethnicity.14' 'Perceived Race or Ethnicity.15' 'race'\n",
      " 'PerceivedRaceorEthnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/yc8lq2qx2ks3ck292tbf6wtm0000gn/T/ipykernel_13584/2589367042.py:10: DtypeWarning: Columns (14,15,18,19,27,49,64,66,68,69,70,71,72,73,74,75,77,92,94,95,96,97,98,99,101,102,103,120,122,123,124,125,126,127,128,129,131,133,148,150,151,154,158,164,166,168,170,176,177,178,179,187,192,194,196,198,205,207,220,222,224,226,233,248,250,252,254,261,262,263,276,278,280,282,289,291) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, index_col=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "PATH = os.getcwd()\n",
    "EXT = \"*.csv\"\n",
    "\n",
    "cols =[]\n",
    "for path, subdir, files in os.walk(PATH):\n",
    "    for file in glob(os.path.join(path, EXT)):\n",
    "        df = pd.read_csv(file, index_col=None)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            cols.append(col)\n",
    "                \n",
    "print(pd.unique([match for match in cols if 'race' in match.lower()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9848718a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no dropped pid dupes\n",
      "starting SJPD is (14945, 9)\n",
      "no dropped pid dupes\n",
      "sj was (23233, 9)\n",
      "sj is merged! SJ shape is now (38178, 9)\n",
      "no dropped pid dupes\n",
      "sj was (12265, 9)\n",
      "sj is merged! SJ shape is now (50443, 9)\n",
      "\n",
      "final saved!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "def convert_simplify_SJ(df):\n",
    "    i = df\n",
    "    i = i.rename(columns={'StopDateTime':'time',\n",
    "                          'StopDate':'date',\n",
    "                          'Date of Stop':'date',\n",
    "                          'StopDateTime':'time',\n",
    "                          'stopTime':'time',\n",
    "                          'Time of Stop':'time',\n",
    "                          \n",
    "                          'officerAssignment_type':'assignment',\n",
    "                          'Officer Type of Assignment':'assignment',\n",
    "                          \n",
    "                          'Is Stop Made in Response to Call for Service':'service call',\n",
    "                          'stopInResponseToCFS':'service call',\n",
    "                          \n",
    "                          'stopDuration':'duration',\n",
    "                          'Duration of Stop':'duration',\n",
    "                          \n",
    "                          'PID':'PID',\n",
    "                          \n",
    "                          'Perceived Race or Ethnicity':'race',\n",
    "                          'Person Perceived Gender Value':'sex',\n",
    "                          'Perceived Gender 1-4':'sex',\n",
    "                          'perceivedAge':'age',\n",
    "                          'Perceived Age':'age',\n",
    "                          \n",
    "                          'Traffic Violation Type':'type',\n",
    "                          \n",
    "                          'Reason for Stop':'reason',\n",
    "                          'Suspicion Sub-Type':'basis',\n",
    "                          'Actions Taken':'actions taken',\n",
    "                          \n",
    "                          'Basis for Search':'search basis',\n",
    "                          'Basis for Property Seizure':'seizure basis',\n",
    "                          'Type of Property Seized':'property seized',\n",
    "                          'Contraband or Evidence':'evidence',\n",
    "                          \n",
    "                          'Results of Stop':'result',\n",
    "                          'Traffic Violation - CJIS Offense Code':'offense code',\n",
    "                          \n",
    "                          'isStudent':'student',\n",
    "                          'Is Serv Call':'service call'})\n",
    "\n",
    "    i = i[(i['service call']!='Y')\\\n",
    "          & (i['assignment']==1)\\\n",
    "          & ((i['type']==1) | (i['type']==2) | (i['type']==3))\\\n",
    "          &  (i['reason']==1)]\n",
    "\n",
    "    i.loc[i['type'] == 1,'type'] = '1 Moving'\n",
    "    i.loc[i['type'] == 2,'type'] = '2 Equipment'\n",
    "    i.loc[i['type'] == 3,'type'] = '3 Non-Moving'\n",
    "    \n",
    "    \n",
    "    race_list = []\n",
    "    for race in i['race']:\n",
    "        try:\n",
    "            if len(race)>2:\n",
    "                race_list.append('mixed')\n",
    "            else:\n",
    "                race_list.append(race)\n",
    "        except:\n",
    "            try:\n",
    "                race_str = race.str.replace(',','')\n",
    "                race_list.append(race_str)\n",
    "            except:\n",
    "                    race_list.append(race)\n",
    "    \n",
    "\n",
    "    \n",
    "    i['race'] = race_list\n",
    "    i['race'] = i['race'].replace(',','', regex=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    try:     \n",
    "        i.loc[i['race'] == '1','race'] = 'asian'\n",
    "        i.loc[i['race'] == '2','race'] = 'black/african american'\n",
    "        i.loc[i['race'] == '3','race'] = 'hispanic/latino(a)'\n",
    "        i.loc[i['race'] == '4','race'] = 'middle eastern or south asian'\n",
    "        i.loc[i['race'] == '5','race'] = 'native american'\n",
    "        i.loc[i['race'] == '6','race'] = 'pacific islander'\n",
    "        i.loc[i['race'] == '7','race'] = 'white'\n",
    "        i.loc[i['race'] == 1,'race'] = 'asian'\n",
    "        i.loc[i['race'] == 2,'race'] = 'black/african american'\n",
    "        i.loc[i['race'] == 3,'race'] = 'hispanic/latino(a)'\n",
    "        i.loc[i['race'] == 4,'race'] = 'middle eastern or south asian'\n",
    "        i.loc[i['race'] == 5,'race'] = 'native american'\n",
    "        i.loc[i['race'] == 6,'race'] = 'pacific islander'\n",
    "        i.loc[i['race'] == 7,'race'] = 'white'\n",
    "    except: \n",
    "        print('race switch failed')\n",
    "        pass\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         i['Date'] = pd.to_datetime(i['Date'])\n",
    "#         i['Time'] = i['Date'].dt.time\n",
    "#     except: \n",
    "#         try: \n",
    "#             i['Time'] = i['Date'].dt.time\n",
    "#         except:\n",
    "#             print('no time changes')\n",
    "#             pass\n",
    "\n",
    "    \n",
    "    try: \n",
    "        i = i.drop_duplicates(subset=['stop_id'], keep='first')\n",
    "    except: \n",
    "        print('no dropped pid dupes')\n",
    "        pass\n",
    "\n",
    "    output_df = i[['date','time','duration','race', 'sex','age','type','search basis','result']]\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "###################################################\n",
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "SJPD = convert_simplify_SJ(pd.read_csv(files[0]))\n",
    "print(f'starting SJPD is {SJPD.shape}')\n",
    "# SJPD.shape\n",
    "\n",
    "for i in files[1:]: \n",
    "    if 'AB953' not in i:\n",
    "        temp_df = convert_simplify_SJ(pd.read_csv(i))\n",
    "        SJPD = pd.merge(SJPD,temp_df,how='outer')\n",
    "\n",
    "        print(f'sj was {temp_df.shape}')\n",
    "        print(f'sj is merged! SJ shape is now {SJPD.shape}')\n",
    "\n",
    "SJPD.to_csv('ALL-SJPD-AB953.csv',index=False)\n",
    "print('\\nfinal saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fd730753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'duration', 'race', 'sex', 'age', 'type',\n",
       "       'search basis', 'result'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SJPD.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3b222",
   "metadata": {},
   "source": [
    "### looking for perceived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a3a82a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c3313b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karatechop\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4163e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022 (CSV)\n"
     ]
    }
   ],
   "source": [
    "cd /Users/karatechop/Documents/GitHub/senior-thesis-pretextual-stops/Data/RIPA-DATA-CA-as-of-2022 (CSV)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4796b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Requests • MuckRock.webloc    \u001b[34mWave 2\u001b[m\u001b[m/\r\n",
      "\u001b[34mIn Progress\u001b[m\u001b[m/                      \u001b[34mWaves 3_4\u001b[m\u001b[m/\r\n",
      "README.md                         working_main.csv\r\n",
      "\u001b[34mWave 1\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d75fb07b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3791210210.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [169]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'{col}\\n{file}\\n\\n')x\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "PATH = os.getcwd()\n",
    "EXT = \"*.csv\"\n",
    "\n",
    "\n",
    "for path, subdir, files in os.walk(PATH):\n",
    "    for file in glob(os.path.join(path, EXT)):\n",
    "        df = pd.read_csv(file, index_col=None)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            col = col.lower()\n",
    "            if 'prior' in col:\n",
    "                print(f'{col}\\n{file}\\n\\n')x\n",
    "                \n",
    "        for col in df.columns:\n",
    "            col = col.lower()\n",
    "            if 'before' in col:\n",
    "                print(f'{col}\\n{file}\\n\\n')\n",
    "        \n",
    "#         print('\\n\\n\\n\\n\\n\\n')\n",
    "                \n",
    "#         for col in df.columns:\n",
    "#             col = col.lower()\n",
    "#             if 'race' in col:\n",
    "#                 print(f'{col}\\n{file}\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88fcf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
